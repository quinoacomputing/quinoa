/*!
  \page      layout Large-data memory layout for equation systems

@tableofcontents{xml}

This page discusses the requirements, design, implementation, and verification
of a data container with zero-cost compile-time-configurable memory layout for
storing a 3-dimensional array of real values. The three dimensions are

1. _Equation_ index, as required for a coupled multi-system equation solver,
2. _Component_ index, a specific scalar component of a system of equations, and
3. _Unknown_ index, as required by some discretization of a numerical solution,
representing field variables at discrete locations, e.g., particles or a mesh
entity such as cell, face, node, etc.

@section layout_req Data layout requirements and design

How should field values, storing particle properties (or solution unknowns in
mesh cells or nodes) should be stored in memory? How should mesh field data
(associated to nodes, elements, faces, etc., in @ref inciter_main) should be
stored in memory? These are the single largest chunks of data a particle-,
and/or mesh-based code operates on. The data layout, i.e., how the data is
stored and organized in memory, determines how the data is accessed and
potentially has a first-degree effect on overall performance.

@section layout_possibilities Possibilities

1. __Unknown-major__, in which various physical properties, e.g., position,
velocity, energy, etc., i.e., the unknowns in a solver, of a single particle or
mesh entity are close to each other in memory.  For example:

\f[[ x1, y1, z1, \dots, x2, y2, z2, \dots, x3, y3, z3, \dots ]\f]

   where the \f$x*\f$ are governed by one equation (e.g., position), the
\f$y*\f$ are governed by another equation (e.g., velocity), and the \f$z*\f$ are
governed by a third equation (e.g., energy), etc. Here the first letter denotes
a physical quantity, while the second is the particle number or mesh entity
index. If the algorithm advances the properties at the unknowns one equation at
a time, data in memory is accessed by having to jump a distance that corresponds
to the number of scalar physical variables per particle or mesh entity. In the
example, the update will have to jump as \f$x1, x2, x3, \dots\f$ are updated.

2. __Property-major__, in which the same type of physical properties are close
to each other in memory. For example,

\f[[ x1, x2, x3, \dots, y1, y2, y3, \dots, z1, z2, z3, \dots ]\f]

   The legend here is the same as in unknown-major: the first letter denotes a
physical quantity, while the second is the particle or mesh entity index. If the
algorithm advances the properties at the unknowns one equation at a time, data
in memory is accessed contiguously in memory as the properties are contiguously
stored.

@section layout_preliminary_discussion Discussion

A property-major storage, case 2 above, seems to be the most efficient at first
sight, as it stores data, as it is read and written by the equation algorithms,
contiguously. However, data access is contiguous only if the particle properties
(or data stored at mesh entities) are independent, i.e., if there is no coupling
among the equations. Unfortunately, this is rarely the case, at least not for
fluid dynamics or any computational physics problem that is interesting enough.
For example in a Lagrangian particle code, velocity is used by the position
update, and velocity is required by the energy update. The same is true for a
mesh-based solver, where the physical variables are coupled, i.e., their update
needs other physical variables at the same mesh entity (and usually that of the
neighbors). Depending on the physical approximation, density (or mass) may be
required for all equations. The stronger the equations are coupled, the more
far-reads are required for a given update with a property-major data layout.
These far-reads are practically always cache misses, as the property-major
storage stores the physical variables for the same particle or mesh entity very
far in memory, e.g., the distance between \f$x1\f$ and \f$y1\f$ is the number of
particles or mesh entities. While the unknown-major storage, case 1 above,
inherently stores data non-contiguously, the distance between properties of a
single particle (or a single mesh entity) is relatively small, i.e., the number
of properties, which may incur less cache misses as several particles (or nodes)
but all of their physical properties at the same unknown could fit into cache.

Assuming strong coupling among the variables, the unknown-major storage will be
favored, but it would be nice if the design allowed for both layouts, so
depending on the type of equations the most appropriate layout could be
selected. If such a design is maintainable, there is still a question whether
the data layout selection should be done at compile-, or run-time.

@section layout_blaze Assessment of the Blaze library that offers a similar choice

Have looked at https://bitbucket.org/blaze-lib/blaze which implements row-, and
column-major matrix classes based on a template argument. See, e.g.,
`<blaze-1.5>/blaze/math/dense/StaticMatrix.h`, which reveals
that the template argument (bool) @code{.cpp}SO@endcode selects between row-, or
column-major internal storage.  Then @code{.cpp}SO@endcode is used at both
compile-time (e.g., by the class-user, when instantiating the type of the
matrix), as well as run-time (e.g., the implementation of
@code{.cpp}isDefault()@endcode). Both compile-time and run-time usage of the SO
template arguments are problematic:

  - The compile-time usage duplicates a lot of code by having to provide similar
    implementations for the element-access @code{.cpp}operator()@endcode of
    @code{.cpp}StaticMatrix@endcode specialized to column-major. There is a
    generic implementation for @code{.cpp}SO@endcode for everything that is
    agnostic of @code{.cpp}SO@endcode, and there is a specialization when
    @code{.cpp}SO@endcode is column-major.

  - The run-time usage also duplicates code by doing an if-test on
    @code{.cpp}SO@endcode in, e.g., @code{.cpp}isDefault()@endcode. Is there a
    better way of doing this? If there are only two types of data layout
    (unknown-, and property-major), code duplication should not be too much of
    an issue. However, the implementation of unknown-property data access must
    be absolutely zero run-time cost. This means the selection must be at
    compile-time and the element access must be absolutely invisible to client
    code. In other words, there must be no re-implementation of a
    time-integrator for an equation just because the data access is different.

@section layout_kokkos Assessment of the Kokkos library that offers a similar choice

Since the first implementation of the configurable data layout, described below,
the Kokkos library, https://github.com/kokkos/kokkos , from Sandia National
Labs, has been released. Kokkos appears to have all the requirements described
here, and many more other features. It does have compile-time configurable data
layouts, @code{.cpp}views@endcode, for the purpose of optimal data access on
various compute devices, such as multi-core CPUs, many-core accelerators, and
Graphics Processing Units. Kokkos appears to provide an excellent abstraction
for data layout abstraction.  However, Kokkos provides a lot more functionality
than just data layout abstraction, e.g., it can generate low level code for
various devices using its configurable views. The currently available Kokkos
back-ends are OpenMP, pthreads, and CUDA. Thus Kokkos provides abstractions for
shared-memory parallelism. While Kokkos has been successfully used in Charm++
code, at this point (Jan 2016) we opt for _not_ adopting Kokkos' views and keep
our original data layout abstractions, discussed below. The reasons:

  - At this point we are too early in the development of Quinoa and its tools to
    be able to say that the current abstractions Charm++ provides are sufficient
    or not to strike the correct balance between performance and productivity.
    In particular, it could be possible that Charm++'s abstractions (using
    overdecomposition), which we use already, are enough. In that case, using a
    single abstraction for parallelism is preferable to two.

  - At this point we would really only need the compile-time configurable data
    layout abstractions from Kokkos and not the other rich features, such as
    abstractions for loop-level shared-memory parallelism.

As far I can tell, the views of an array in Kokkos provide a very similar
abstraction for data layout and thus memory access what is described below.

@section layout_requirements Requirements

@m_div{m-block m-center-m m-note}
Is it possible to implement a compile-time configurable data-access policy via a
thin data-access interface with zero run-time cost, no code-duplication, and in
a way that is invisible to client code? __Yes.__ See below.
@m_enddiv

Zero-cost is achieved via type-based compile-time polymorphism. This is
controlled via a cmake variable.

The particle (or mesh entity) data is a logically 3-dimensional array that
stores the particle properties or unknowns at mesh entities, e.g., faces, cell
centers, nodes, etc.

For clarity, the discussion below will use the expression "particle" for a
particle-code and will not specifically mention mesh-based unknowns, stored at
the nodes, elements, faces, etc., of a computational mesh. The former is for a
particle-code, the latter is for a mesh-code. The data layout discussion is
independent of whether particles or mesh entities (nodes, cells, etc.) are used.

In principle there are a total of 6 permutations:

    1. ParEqComp: [ particle ] [ equation ] [ component ]
    2. ParCompEq: [ particle ] [ component ] [ equation ]
    3. EqCompPar: [ equation ] [ component ] [ particle ]
    4. EqParComp: [ equation ] [ particle ] [ component ]
    5. CompEqPar: [ component ] [ equation ] [ particle ]
    6. CompParEq: [ component ] [ particle ] [ equation ]

Of these 6 we only consider those where _component_ follows _equation_. (For
those layouts where _equation_ follows _component_ the access would be
unnecessarily complicated by the potentially unequal number of components for
different equations which is not known at compile-time and thus does not allow
some optimizations.) This decision leaves us with the following choices:

    1. ParEqComp: [ particle ] [ equation ] [ component ]
    3. EqCompPar: [ equation ] [ component ] [ particle ]
    4. EqParComp: [ equation ] [ particle ] [ component ]

Access is based on the 3 coordinates: _particle_ (or _unknown_), _component_,
and _offset_. _Particle_ is the particle index, component denotes the given
component of a vector equation, e.g., velocity has 3 components, a
multi-material turbulent mix model governed by the Dirichlet SDE has \f$K=N-1\f$
scalars (components), and _offset_ is determined by the relative position of the
given equation compared to the other equations. Using these 3 coordinates the
index calculations for the above 3 cases are:

    1. ParEqComp: [ particle ] [ equation ] [ component ]

         baseptr + particle*nprop + offset + component

where _nprop_ is the total number of particle properties, e.g., 3 positions, 3
velocities, 5 scalars \f$\to\f$ nprop = 11.

    3. EqCompPar: [ equation ] [ component ] [ particle ]

         baseptr + (offset+component)*npar + particle

where _npar_ is the total number of particles.

    4. EqParComp: [ equation ] [ particle ] [ component ]

         baseptr + offset*npar + nce*particle + component

where _nce_ is the number of components for the given equation. Since this would
require another function argument (besides _particle_, _component_, and
_offset_), and it costs an integer-multiply more than the other two layouts, we
dismiss this layout, and only implement the following two:

    1. ParEqComp - Particle-major
    3. EqCompPar - Equation-major

These options are exposed via a cmake variable and can be switched
before a build.

@section layout_asm Data layout implementation and assembly

This section documents the implementation and the assembly code, produced by the
compilers, of the compile-time configurable data-access policy discussed above.
The implementation is via a thin data-access interface with zero run-time cost,
no code-duplication, and in a way that is invisible to client code.

@subsection layout_zerocost Zero-runtime-cost data-layout wrappers with type-based compile-time dispatch

Tags for selecting particle-, or property-major data layout policies:

@code{.cpp}
const bool ParticleMajor = true;
const bool PropertyMajor = false;
@endcode

Essentially, the implementation is as follows:

@code{.cpp}
template< bool Major >
class Data {

  private:
   // Transform a compile-time bool into a type
   template< bool m >
   struct int2type {
     enum { value = m };
   };

   // Overloads for particle-, and property-major accesses
   inline
   tk::real& access( int particle, int property, int2type<ParticleMajor> ) {
     return *(m_ptr + particle*m_nprop + m_offset + property);
   }
   inline
   tk::real& access( int particle, int property, int2type<PropertyMajor> ) {
     // This is the same for now, not called, irrelevant in zero-cost-test
     return *(m_ptr + particle*m_nprop + m_offset + property);
   }

   tk::real* const m_ptr;
   const int m_nprop;
   const int m_offset;

  public:
    // Constructor
    Data( tk::real* const ptr, int nprop, int offset ) :
      m_ptr(ptr), m_nprop(nprop), m_offset(offset) {}

    // Access dispatch
    inline tk::real& operator()( int particle, int property ) {
      return access( particle, property, int2type<Major>() );
    }
};
@endcode

@subsection layout_test Test of zero-cost

Test by adding to @code{.cpp}Dirichlet@endcode (derived equation class)
constructor (client code):

@code{.cpp}
Data< Layout > d( particles, m_nprop, m_offset );
Model::aa = d( 34, 3 );
Model::bb = *(m_particles + 34*m_nprop + m_offset + 3);
@endcode

Add to @code{.cpp}Model@endcode:

@code{.cpp}
Model {
  ...
  public:
    tk::real aa;
    tk::real bb;
  ...
}
@endcode

Add to @code{.cpp}Physics@endcode constructor:

@code{.cpp}
std::cout << m_mix->aa << m_mix->bb;
@endcode

This is so the optimizing compiler cannot entirely optimize the assignments of
@code{.cpp}aa@endcode and @code{.cpp}bb@endcode away.

@subsection layout_debugasm Debug assembly

Generated assembly code with @code{.cmake}CMAKE_BUILD_TYPE=DEBUG@endcode (i.e.,
without optimization) of the assignments of @code{.cpp}aa@endcode (line 42) and
@code{.cpp}bb@endcode (line 43) in @code{.cpp}Dirichlet@endcode's constructor,
with @code{.sh}clang -g -S -mllvm --x86-asm-syntax=intel@endcode, gnu and intel
generate very similar code:

@code{.asm}
     .loc    143 42 20  ; <quinoa>/src/DiffEq/Dirichlet.h:42:20
.Ltmp27038:
     lea     RDI, QWORD PTR [RBP - 56]
     mov     ESI, 34
     mov     EDX, 3
     call    _ZN6quinoa4DataILb1EEclEii
.Ltmp27039:
     mov     QWORD PTR [RBP - 176], RAX # 8-byte Spill
     jmp     .LBB2550_7
.LBB2550_7:
     mov     RAX, QWORD PTR [RBP - 176] # 8-byte Reload
     movsd   XMM0, QWORD PTR [RAX]
     mov     RCX, QWORD PTR [RBP - 64] # 8-byte Reload
     movsd   QWORD PTR [RCX + 8], XMM0
     .loc    143 43 0    ; <quinoa>/src/DiffEq/Dirichlet.h:43:0
     mov     RDX, QWORD PTR [RCX + 32]
     imul    ESI, DWORD PTR [RCX + 48], 34
     movsxd  RDI, ESI
     shl     RDI, 3
     add     RDX, RDI
     movsxd  RDI, DWORD PTR [RCX + 52]
     movsd   XMM0, QWORD PTR [RDX + 8*RDI + 24]
     movsd   QWORD PTR [RCX + 16], XMM0
@endcode

Line 42 translates to register loads and a function call into
@code{.cpp}tk::Data@endcode, while line 43 translates to some integer arithmetic
of the address and loads.

@subsection layout_excerpt1 Excerpt from the Intel® 64 and IA-32 Architectures Software Developer Manual

> The LEA (load effective address) instruction computes the effective address in
> memory (offset within a segment) of a source operand and places it in a
> general-purpose register. This instruction can interpret any of the
> processor’s addressing modes and can perform any indexing or scaling that may
> be needed. It is especially useful for initializing the ESI or EDI registers
> before the execution of string instructions or for initializing the EBX
> register before an XLAT instruction.
> 
> The MOVSXD instruction operates on 64-bit data. It sign-extends a 32-bit value
> to 64 bits. This instruction is not encodable in non-64-bit modes.
> 
> A common type of operation on packed integers is the conversion by zero- or
> sign-extension of packed integers into wider data types. SSE4.1 adds 12
> instructions that convert from a smaller packed integer type to a larger
> integer type (PMOVSXBW, PMOVZXBW, PMOVSXBD, PMOVZXBD, PMOVSXWD, PMOVZXWD,
> PMOVSXBQ, PMOVZXBQ, PMOVSXWQ, PMOVZXWQ, PMOVSXDQ, PMOVZXDQ). The source
> operand is from either an XMM register or memory; the destination is an XMM
> register.
> 
> IMUL Signed multiply. The IMUL instruction multiplies two signed integer
> operands. The result is computed to twice the size of the source operands;
> however, in some cases the result is truncated to the size of the source
> operands.
> 
> SAL/SHL Shift arithmetic left/Shift logical left. The SAL (shift arithmetic
> left), SHL (shift logical left), SAR (shift arithmetic right), SHR (shift
> logical right) instructions perform an arithmetic or logical shift of the bits
> in a byte, word, or doubleword. The SAL and SHL instructions perform the same
> operation. They shift the source operand left by from 1 to 31 bit positions.
> Empty bit positions are cleared. The CF flag is loaded with the last bit
> shifted out of the operand.

@subsection layout_optasm Optimized assembly

Generated assembly code with
@code{.cmake}CMAKE_BUILD_TYPE=RELWITHDEBINFO@endcode (i.e., with optimization)
of the assignments of @code{.cpp}aa@endcode (line 42) and @code{.cpp}bb@endcode
(line 43) in @code{.cpp}Dirichlet@endcode's constructor, with
@code{.sh}clang -O2 -g DNDEBUG -S -mllvm --x86-asm-syntax=intel@endcode, gnu
and intel generate very similar optimized code:

@code{.asm}
     .loc    144 42 20  ; <quinoa>/src/DiffEq/Dirichlet.h:42:20
     movsd   XMM0, QWORD PTR [R14 + 8*RAX + 24]
     movsd   QWORD PTR [R13 + 8], XMM0
     .loc    144 43 0    ; <quinoa>/src/DiffEq/Dirichlet.h:43:0
     mov     RCX, QWORD PTR [R13 + 32]
     movsd   XMM0, QWORD PTR [RCX + 8*RAX + 24]
     movsd   QWORD PTR [R13 + 16], XMM0
@endcode

Both lines 42 and 43 translate to very similar SSE loads with pointer
arithmetic, i.e., line 42 costs the same as line 43.

@subsection layout_excerpt2 Excerpt from the Intel® 64 and IA-32 Architectures Software Developer Manual

> The MOVS instruction moves the string element addressed by the ESI register to
> the location addressed by the EDI register. The assembler recognizes three
> “short forms” of this instruction, which specify the size of the string to be
> moved: MOVSB (move byte string), MOVSW (move word string), and MOVSD (move
> doubleword string).
> 
> The MOVSD (move scalar double-precision floating-point) instruction transfers
> a 64-bit double-precision floating- point operand from memory to the low
> quadword of an XMM register or vice versa, or between XMM registers.
> Alignment of the memory address is not required, unless alignment checking is
> enabled.

@section layout_benchmark Data layout benchmark

This section documents the benchmark of the implementation of the compile-time
configurable data-access policy discussed above. The implementation is via a
thin data-access interface with zero run-time cost, no code-duplication, and in
a way that is invisible to client code.

@subsection layout_input Quinoa::Walker input file used for the benchmark

Note that walker is no longer part of Quinoa. But you can still browse its
documentation at https://quinoacomputing.org/archive.

We will integrate for the duration of a 100,000 time steps a system of 100
coupled non-linear stochastic differential equations (SDEs) whose statistically
stationary solution converge to the Dirichlet distribution and measure the
wall-clock time. For more on the Dirichlet SDE, see [src/DiffEq/Dirichlet.h](https://github.com/quinoacomputing/quinoa/blob/master/src/DiffEq/Dirichlet.h).

@code{.bash}
walker

  nstep 100000  # Max number of time steps
  term  140.0   # Max time
  dt    0.05    # Time step size
  npar  40000   # Number of particles

  ttyi  100     # TTY output interval

  rngs
    mkl_mrg32k3a seed 0 end
  end

  dirichlet
    ncomp 100  # = K = N-1
    b     0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
          0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5 0.1 1.5
    end
    S     0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
          0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4 0.625 0.4
    end
    kappa 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
          0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3 0.0125 0.3
    end
    rng mkl_mrg32k3a
  end

  statistics    # Estimate statistics
    <Y1>        # mean of Y1
    <Y2>
    <y1y1>      # variance of Y1 = <(Y1-<Y1>)^2> = <y1^2>
    <y2y2>
    <y1y2>
  end

end
@endcode

@subsection layout_ptr Ptr - Working with raw pointers

This algorithm gets the starting raw pointer from which the given particle data
is (contiguously) accessible in memory and simply adds integers to the address
to access and update the 100 components specified above. The algorithm assumes a
particular data layout -- it only works with the particle-major storage -- a
logically 3-dimensional array with [ particle ] [ equation ] [ component ]
layout.

__Layout-dependent algorithm:__

@code{.cpp}
//! Advance particles
void advance(int p, int tid, tk::real dt) override {
  // Get access to particle scalars
  tk::real* y = m_particles.ptr() + p*m_nprop + m_offset;
  
  // Compute Nth scalar
  tk::real yn = 1.0 - y[0];
  for (int i=1; i<m_ncomp; ++i) yn -= y[i];
  
  // Generate Gaussian random numbers with zero mean and unit variance
  tk::real dW[m_ncomp];
  m_rng->gaussian( tid, m_ncomp, dW );
  
  // Advance first m_ncomp (K=N-1) scalars
  for (int i=0; i<m_ncomp; ++i) {
    tk::real d = m_k[i]*y[i]*yn*dt;
    if (d > 0.0) d = sqrt(d); else d = 0.0;
    y[i] += 0.5*m_b[i]*(m_S[i]*yn - (1.0-m_S[i])*y[i])*dt + d*dW[i];
  }
}
@endcode

@subsection layout_par Par - Access via particle-major layout policy

This algorithm accesses particle data via the wrapper class,
@code{.cpp}tk::Data@endcode, in a data-layout-agnostic fashion. Access itself
via this class is demonstrably "zero-cost", i.e., an optimizing compiler
completely optimizes the abstraction away: see @ref layout_asm for the assembly
generated by 3 compilers.  However, writing an SDE-advance algorithm in a
data-layout-agnostic manner, requires index calculations at every
particle-access compared to working with raw pointers, as described above. Thus
the following tests are designed to measure only the additional index
calculations that the layout-agnostic access entails.

__Layout-independent algorithm:__

@code{.cpp}
//! Advance particles
void advance(int p, int tid, tk::real dt) override {
  // Compute Nth scalar
  tk::real yn = 1.0 - m_particles(p, 0, m_offset);
  for (int i=1; i<m_ncomp; ++i) yn -= m_particles(p, i, m_offset);

  // Generate Gaussian random numbers with zero mean and unit variance
  tk::real dW[m_ncomp];
  m_rng->gaussian( tid, m_ncomp, dW );

  // Advance first m_ncomp (K=N-1) scalars
  for (int i=0; i<m_ncomp; ++i) {
    tk::real d = m_k[i] * m_particles(p, i, m_offset) * yn * dt;
    if (d > 0.0) d = sqrt(d); else d = 0.0;
    m_particles(p, i, m_offset) +=
      0.5*m_b[i]*(m_S[i]*yn - (1.0-m_S[i]) * m_particles(p, i, m_offset) )*dt
      + d*dW[i];
  }
}
@endcode

@subsection layout_comparison Comparison of the algorithms

@code{.cmake}DEBUG@endcode mode uses @code{.bash}-O0@endcode and does not
optimize function calls away for all of three compilers tested.
@code{.cmake}RELEASE@endcode mode uses @code{.bash}-O3@endcode and the
abstraction is completely optimized away. However, index calculations still
remain compared to a layout-dependent advance algorithm.

Total time measured in micro-seconds, run on a Lenovo laptop with Intel Core i7,
8 compute cores:
       Run           | Ptr              | Par              | Par/Ptr
       :------------ | ---------------: | ---------------: | ----------------:
       clang/DEBUG   | 150350236        | 338851735        | 2.2537 x slowdown
       clang/RELEASE |  98157742        | 104077139        | 1.0603 x slowdown
       DEBUG/RELEASE | 1.5317 x speedup | 3.2558 x speedup | n/a

       Run           | Ptr              | Par              | Par/Ptr
       :------------ | ---------------: | ---------------: | ----------------:
       gnu/DEBUG     | 161603164        | 386646353        | 2.3926 x slowdown
       gnu/RELEASE   |  94747953        |  98187568        | 1.0363 x slowdown
       DEBUG/RELEASE | 1.7056 x speedup | 3.9378 x speedup | n/a

       Run           | Ptr              | Par              | Par/Ptr
       :------------ | ---------------: | ---------------: | ----------------:
       intel/DEBUG   | 171691440        | 608407412        | 3.5436 x slowdown
       intel/RELEASE |  90059133        |  89892665        | 0.99815 x speedup
       DEBUG/RELEASE | 1.9064 x speedup | 6.7682 x speedup | n/a

@subsection layout_asm_discussion Data layout benchmark discussion

- As expected, inlining has a significant effect on performance: going from
  @code{.cmake}DEBUG@endcode to @code{.cmake}RELEASE@endcode mode yields a
  significant speedup with all three compilers, see last,
  @code{.cmake}DEBUG@endcode/@code{.cmake}RELEASE@endcode, rows.

- As expected, the additional index calculations required by layout-agnostic
  access do take a performance hit: though only 6% with clang, and 3% with gnu,
  see last, _Par/Ptr_, columns.

- Surprisingly, the layout-agnostic access is even a tiny bit faster than the
  layout-dependent algorithm with the Intel compiler with
  @code{.bash}-O3@endcode.

@section layout_conclusion Conclusion

As the implementation is not a significant performance hit, the equation
advancement algorithms and particle-, and mesh-property data access are used
only via the data-layout-independent interface. The data layout can be changed
at compile time. Data access is abstracted (and optimized) away.

Note that the above discussion is independent of whether a particle-code or a
mesh-code is used. From the data layout viewpoint the particle-major and
mesh-field-major are equivalent and in the code, and in tk::Data, this is called
the _unknown_-major. See [src/Base/Data.h](https://github.com/quinoacomputing/quinoa/blob/master/src/Base/Data.h) and its specializations in [src/Base/Fields.h](https://github.com/quinoacomputing/quinoa/blob/master/src/Base/Fields.h) and
[src/Base/Particles.h](https://github.com/quinoacomputing/quinoa/blob/master/src/Base/Particles.h).
The data layouts for mesh-fields and particles can be configured independently
at compile time via cmake variables @code{.cmake}PARTICLE_DATA_LAYOUT@endcode
and @code{.cmake}FIELD_DATA_LAYOUT@endcode, see also
[cmake/ConfigureDataLayout.cmake](https://github.com/quinoacomputing/quinoa/blob/master/cmake/ConfigureDataLayout.cmake).

For the API, see tk::Data, and for the full (and current) implementation, see [src/Base/Data.h](https://github.com/quinoacomputing/quinoa/blob/master/src/Base/Data.h).
*/
